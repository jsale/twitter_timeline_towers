{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get User Timeline Tweets\n",
    "## This script takes an array of usernames, reads folders of JSON files containing the user's most recent 3200 tweets, and outputs ANTz visualizations of timeline towers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on 2022-12-14\n",
    "\n",
    "@author: jsale\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Twitter user array containing list of users to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example lists containing twitter users\n",
    "# twitter_user_array = ['TheEllenShow','YouTube','narendramodi','KimKardashian','selenagomez','jtimberlake','cnnbrk','BillGates','britneyspears','CNN','neymarjr','ddlovato','shakira','jimmyfallon','nytimes','KingJames','NASA','BBCBreaking','SrBachchan','mileycyrus','JLo','PMOIndia','imVkohli','Oprah','BrunoMars','BeingSalmanKhan','akshaykumar','iamsrk','NiallOfficial','BTS_twt','Drake','KylieJenner','realmadrid','FCBarcelona','SportsCenter','espn','ChampionsLeague','Harry_Styles','KevinHart4real','wizkhalifa']\n",
    "# twitter_user_array = ['PaulEDawson','UNFCCC','SpeakerPelosi','jessphoenix2018','MarkRuffalo','SenMarkey','SenWhitehouse','MikeHudema','ed_hawkins','TravelWithXtina','WMO','Jackthelad1947','UNEP',' AOC','votevets','PeterGleick','ProfStrachan']\n",
    "\n",
    "test = ['CBSMornings','nytimes','TechCrunch']\n",
    "# Set the twitter_user_array equal to one of the example lists\n",
    "twitter_user_array = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folders to contain ANTz executable and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# ANTz folder creation\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "for i in range(len(twitter_user_array)):\n",
    "    # This example uses an antz subfolder, not required\n",
    "    new_dir = cwd_path + \"/antz/\" + twitter_user_array[i]\n",
    "    try:\n",
    "        os.mkdir(new_dir)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % new_dir)\n",
    "    else:\n",
    "        print (\"Directory %s successfully created.\" % new_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate newly created folders with ANTz executables and dependencies for mac and pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Copy ANTz files from default version to new folder(s) created in previous cell\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "#Define array of Twitter accounts to visualize\n",
    "# twitter_user_array = ['taylorswift13','ArianaGrande','ladygaga','TheEllenShow','YouTube','narendramodi','KimKardashian','selenagomez','jtimberlake','cnnbrk','BillGates','britneyspears','CNN','neymarjr','ddlovato','shakira','jimmyfallon','nytimes','KingJames','NASA','BBCBreaking','SrBachchan','mileycyrus','JLo','PMOIndia','imVkohli','Oprah','BrunoMars','BeingSalmanKhan','akshaykumar','iamsrk','NiallOfficial','BTS_twt','Drake','KylieJenner','realmadrid','FCBarcelona','SportsCenter','espn','ChampionsLeague','Harry_Styles','KevinHart4real','wizkhalifa']\n",
    "cwdpath = os.getcwd()\n",
    "for i in range(len(twitter_user_array)):\n",
    "    print('Working on ' + twitter_user_array[i])\n",
    "    # copy subdirectory containing all ANTz files\n",
    "    fromDirectory = cwdpath + \"/antz_files_mac_and_pc\"\n",
    "    toDirectory = cwdpath + \"/zips/\" + twitter_user_array[i]\n",
    "\n",
    "    copy_tree(fromDirectory, toDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "\n",
    "\"\"\"\n",
    "Initialize date variables\n",
    "\"\"\"\n",
    "days_per_month = {'Jan':31,'Feb':28,'Mar':31,'Apr':30,'May':31,'Jun':30,'Jul':31,'Aug':31,'Sep':30,'Oct':31,'Nov':30,'Dec':31}\n",
    "days_per_month_cumulative = {'Jan':0,'Feb':31,'Mar':59,'Apr':90,'May':120,'Jun':151,'Jul':181,'Aug':212,'Sep':243,'Oct':273,'Nov':304,'Dec':334}\n",
    "days_per_numeric_month_cumulative = {1:0,2:31,3:59,4:90,5:120,6:151,7:181,8:212,9:243,10:273,11:304,12:334}\n",
    "days_per_string_numeric_month_cumulative = {'01':0,'02':31,'03':59,'04':90,'05':120,'06':151,'07':181,'08':212,'09':243,'10':273,'11':304,'12':334}\n",
    "\n",
    "##########################\n",
    "\n",
    "\"\"\"\n",
    "Define color palettes\n",
    "\"\"\"\n",
    "colortable = {}\n",
    "colortable[0] = \"255,0,0\" # red\n",
    "colortable[1] = \"0,255,0\" # green\n",
    "colortable[2] = \"0,0,255\" # blue\n",
    "colortable[3] = \"0,255,255\" # cyan\n",
    "colortable[4] = \"255,0,255\" # magenta\n",
    "colortable[5] = \"255,255,0\" # yellow\n",
    "colortable[6] = \"255,153,0\" # orange\n",
    "colortable[7] = \"255,0,102\" # hot pink\n",
    "colortable[8] = \"0,255,102\" # dark cyan\n",
    "colortable[9] = \"0,155,0\"  # dark green\n",
    "colortable[10] = \"128,0,128\" # deep purple\n",
    "colortable[11] = \"0,180,180\" # turquoise\n",
    "colortable[12] = \"204,102,0\" # brown\n",
    "colortable[13] = \"153,0,0\" # deep red\n",
    "colortable[14] = \"0,115,115\"  # dark turquoise\n",
    "colortable[15] = \"0,225,225\"  #  med cyan\n",
    "colortable[16] = \"190,190,190\"  # light gray\n",
    "colortable[17] = \"255,255,255\"  # white\n",
    "colortable[18] = \"100,100,255\"  # light blue\n",
    "colortable[19] = \"255,180,255\"  # light purple\n",
    "colortable[20] = \"255,200,0\"  # gold\n",
    "colortable[21] = \"0,100,120\"  # ??\n",
    "colortable[22] = \"40,100,180\" # ??\n",
    "colortable[23] = \"80,100,220\" # ??\n",
    "colortable[24] = \"100,255,100\"  # light green\n",
    "colortable[25] = \"100,100,100\"  # dark gray\n",
    "colortable[26] = \"127,127,127\"  # medium gray\n",
    "colortable[27] = \"34,89,222\"  # \n",
    "colortable[28] = \"222,89,34\"  # \n",
    "colortable[29] = \"66,199,0\"  # \n",
    "colortable[30] = \"45,160,0\"  # \n",
    "colortable[31] = \"100,50,50\"  # \n",
    "colortable[32] = \"20,20,150\"  # \n",
    "colortable[33] = \"0,0,0\"  # black\n",
    "\n",
    "firecolortable = []\n",
    "firecolortable.append(\"255,0,0\")\n",
    "firecolortable.append(\"255,20,0\")\n",
    "firecolortable.append(\"255,40,0\")\n",
    "firecolortable.append(\"255,60,0\")\n",
    "firecolortable.append(\"255,80,0\")\n",
    "firecolortable.append(\"255,100,0\") \n",
    "firecolortable.append(\"255,120,0\")\n",
    "firecolortable.append(\"255,160,0\")\n",
    "firecolortable.append(\"255,200,0\")\n",
    "firecolortable.append(\"255,220,0\") \n",
    "firecolortable.append(\"255,255,0\")\n",
    "firecolortable.append(\"255,255,0\") \n",
    "firecolortable.append(\"255,255,50\") \n",
    "firecolortable.append(\"255,255,100\") \n",
    "firecolortable.append(\"255,255,150\")  \n",
    "firecolortable.append(\"255,255,200\")  \n",
    "firecolortable.append(\"255,255,255\")\n",
    "\n",
    "prismcolortable = []\n",
    "prismcolortable.append(\"255,0,0\")\n",
    "prismcolortable.append(\"255,125,0\")\n",
    "prismcolortable.append(\"255,255,0\")\n",
    "prismcolortable.append(\"0,255,0\")\n",
    "prismcolortable.append(\"0,255,255\")\n",
    "prismcolortable.append(\"0,0,255\")\n",
    "prismcolortable.append(\"255,0,255\")\n",
    "prismcolortable.append(\"255,255,255\")\n",
    "\n",
    "utc_offset_color_index = {}\n",
    "utc_offset_color_index[-25200] = 0\n",
    "utc_offset_color_index[-14400] = 1\n",
    "utc_offset_color_index[-18000] = 2\n",
    "utc_offset_color_index[-21600] = 3\n",
    "utc_offset_color_index[-10800] = 4\n",
    "utc_offset_color_index[3600] = 5\n",
    "utc_offset_color_index[-28800] = 6\n",
    "utc_offset_color_index[7200] = 7\n",
    "utc_offset_color_index[-36000] = 8\n",
    "utc_offset_color_index[36000] = 9\n",
    "utc_offset_color_index[-39600] = 10\n",
    "utc_offset_color_index[28800] = 11\n",
    "utc_offset_color_index[10800] = 12\n",
    "utc_offset_color_index[-7200] = 13\n",
    "utc_offset_color_index[25200] = 14\n",
    "utc_offset_color_index[16200] = 15\n",
    "utc_offset_color_index[43200] = 16\n",
    "utc_offset_color_index[34200] = 17\n",
    "utc_offset_color_index[19800] = 18\n",
    "utc_offset_color_index[0] = 19\n",
    "utc_offset_color_index[32400] = 20\n",
    "utc_offset_color_index[46800] = 21\n",
    "utc_offset_color_index[-32400] = 22\n",
    "utc_offset_color_index[39600] = 23\n",
    "utc_offset_color_index[14400] = 24\n",
    "utc_offset_color_index[-9000] = 25\n",
    "\n",
    "#########################################\n",
    "\n",
    "\"\"\"\n",
    "Initialize ANTz Node parameters\n",
    "\"\"\"\n",
    "\n",
    "# Initialize all ANTz Node variables\n",
    "id = 0\n",
    "type = 5\n",
    "data = id\n",
    "selected = 0\n",
    "parent_id = 0\n",
    "branch_level = 0\n",
    "child_id = id\n",
    "child_index = 0\n",
    "child_count = 0\n",
    "ch_input_id = 0\n",
    "ch_output_id = 0\n",
    "ch_last_updated = 0\n",
    "average = 0\n",
    "interval = 1\n",
    "aux_a_x = 0\n",
    "aux_a_y = 0\n",
    "aux_a_z = 0\n",
    "aux_b_x = 0\n",
    "aux_b_y = 0\n",
    "aux_b_z = 0\n",
    "color_shift = 0\n",
    "rotate_vec_x = 0\n",
    "rotate_vec_y = 0\n",
    "rotate_vec_z = 0\n",
    "rotate_vec_s = 1\n",
    "scale_x = 0\n",
    "scale_y = 0\n",
    "scale_z = 0\n",
    "translate_x = 0\n",
    "translate_y = 0\n",
    "translate_z = 0\n",
    "tag_offset_x = 0\n",
    "tag_offset_y = 0\n",
    "tag_offset_z = 0\n",
    "rotate_rate_x = 0\n",
    "rotate_rate_y = 0\n",
    "rotate_rate_z = 0\n",
    "rotate_x = 0\n",
    "rotate_y = 0\n",
    "rotate_z = 0\n",
    "scale_rate_x = 0\n",
    "scale_rate_y = 0\n",
    "scale_rate_z = 0\n",
    "translate_rate_x = 0\n",
    "translate_rate_y = 0\n",
    "translate_rate_z = 0\n",
    "translate_vec_x = 0\n",
    "translate_vec_y = 0\n",
    "translate_vec_z = 0\n",
    "shader = 0\n",
    "geometry = 3\n",
    "line_width = 1\n",
    "point_size = 0\n",
    "ratio = 0.1\n",
    "color_index = 0\n",
    "color_r = 110\n",
    "color_g = 110\n",
    "color_b = 110\n",
    "color_a = 255\n",
    "color_fade = 0\n",
    "texture_id = 0\n",
    "hide = 0\n",
    "freeze = 0\n",
    "topo = 2\n",
    "facet = 0\n",
    "auto_zoom_x = 0\n",
    "auto_zoom_y = 0\n",
    "auto_zoom_z = 0\n",
    "trigger_hi_x = 0\n",
    "trigger_hi_y = 0\n",
    "trigger_hi_z = 0\n",
    "trigger_lo_x = 0\n",
    "trigger_lo_y = 0\n",
    "trigger_lo_z = 1\n",
    "set_hi_x = 0\n",
    "set_hi_y = 0\n",
    "set_hi_z = 0\n",
    "set_lo_x = 0\n",
    "set_lo_y = 0\n",
    "set_lo_z = 0\n",
    "proximity_x = 0\n",
    "proximity_y = 0\n",
    "proximity_z = 0\n",
    "proximity_mode_x = 0\n",
    "proximity_mode_y = 0\n",
    "proximity_mode_z = 0\n",
    "segments_x = 16\n",
    "segments_y = 16\n",
    "segments_z = 0\n",
    "tag_mode = 0\n",
    "format_id = 0\n",
    "table_id = 0\n",
    "record_id = id\n",
    "size = 420\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through folders, read JSON tweet data, output ANTz timeline tower visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################################\n",
    "# Main Loop to generate ANTz timeline tower visualizations\n",
    "\n",
    "for bot_inc in range(len(twitter_user_array)):\n",
    "    pprint(\"bot_inc:\" + str(bot_inc) + \" | Working on user \" + twitter_user_array[bot_inc])\n",
    "\n",
    "    # Create all_tweets array containing all 3200 tweets for each user\n",
    "    all_tweets = []\n",
    "    inc = 0\n",
    "    val = 0\n",
    "    val_inc = 0\n",
    "    dir = cwd_path + '/timelines/myfollowers_tweets/' + twitter_user_array[bot_inc] + '/'\n",
    "    filenames = next(os.walk(dir))[2]\n",
    "    for filename in filenames:\n",
    "        print(filename)\n",
    "        with open(dir + filename, 'r', encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            if 'data' in data:\n",
    "                for tweet in data['data']:\n",
    "                    all_tweets.append(tweet)\n",
    "\n",
    "                    # Increment variables to track progress, mostly for very large files\n",
    "                    inc += 1\n",
    "                    val_inc += 1\n",
    "                    if val_inc > 100:\n",
    "                        val = val + 100\n",
    "    #                     print(str(val))\n",
    "                        val_inc = 0\n",
    "\n",
    "    \n",
    "    ##########################################\n",
    "\n",
    "    \"\"\"\n",
    "    Normalize range of tweet creation dates to timeline tower height\n",
    "    \"\"\"\n",
    "    # Initialize increments\n",
    "    min_days = {}\n",
    "    max_days = {}\n",
    "    days_diff = {}\n",
    "    num_tweets = {}\n",
    "    i = 0\n",
    "    x_inc = 0\n",
    "    y_inc = 0\n",
    "\n",
    "    num_tweets[twitter_user_array[bot_inc]] = 0\n",
    "    min_days2 = 9999999999999999999999999\n",
    "    max_days2 = 0\n",
    "    pprint(\"i:\" + str(i) + \" | Working on user \" + twitter_user_array[bot_inc])\n",
    "\n",
    "    for tweet in all_tweets:\n",
    "        num_tweets[twitter_user_array[bot_inc]] += 1\n",
    "        # Parse the date and time into seconds for total_time and use for translate_y\n",
    "        date_str = tweet['created_at']\n",
    "        year = int(date_str[0:4])\n",
    "        month = int(date_str[5:7])\n",
    "        day = int(date_str[8:10])\n",
    "        hour = int(date_str[11:13])\n",
    "        minute = int(date_str[14:16])\n",
    "        second = int(date_str[17:19])\n",
    "        # Optional print statement to check work\n",
    "#         print(str(year)+\"/\"+str(month)+\"/\"+str(day)+\" \"+str(hour)+\":\"+str(minute)+\":\"+str(second))\n",
    "        hour_seconds = hour * 3600\n",
    "        minute_seconds = minute * 60\n",
    "        seconds = second * 1\n",
    "        total_time = (float(seconds) + float(minute_seconds) + float(hour_seconds)) * 360/86400\n",
    "\n",
    "        year_days = (float(year)-2006) * 365\n",
    "        month_days = days_per_numeric_month_cumulative[month]\n",
    "        days = float(day)\n",
    "        total_days = year_days + month_days + days\n",
    "\n",
    "        if total_days < min_days2:\n",
    "            min_days2 = total_days\n",
    "            min_days[twitter_user_array[bot_inc]] = total_days\n",
    "        if total_days > max_days2:\n",
    "            max_days2 = total_days\n",
    "            max_days[twitter_user_array[bot_inc]] = total_days\n",
    "        days_diff[twitter_user_array[bot_inc]] = max_days2 - min_days2\n",
    "        \n",
    "###########################################\n",
    "\n",
    "    \"\"\"\n",
    "    Export to ANTz timeline tower\n",
    "    \"\"\"\n",
    "    cwd_path = os.getcwd()\n",
    "    # Loop Through Tweets of Most Common Users and Output to ANTz Node and Tag Files\n",
    "    # Define destination folder locations for old an new versions of ANTz\n",
    "    new_dir1 = cwd_path + \"/zips/\" + twitter_user_array[bot_inc] + \"/usr/csv\"\n",
    "    new_dir2 = cwd_path + \"/zips/\" + twitter_user_array[bot_inc] + \"/usr/antz0001/csv\"\n",
    "\n",
    "    # Optional print statement to check work\n",
    "    # pprint(\"i:\" + str(i) + \" | Working on user \" + twitter_user_array[bot_inc])\n",
    "\n",
    "    # Open ANTz Node files for writing, one each for old and new versions of ANTz\n",
    "    fout1 = open(new_dir1 + \"/antz0001node.csv\",\"w\")\n",
    "    fout2 = open(new_dir2 + \"/antz0001node.csv\",\"w\")\n",
    "\n",
    "    # Open the Tag files to add metadata to ANTz objects\n",
    "    ftag1 = open(new_dir1 + \"/antz0001tag.csv\",\"w\")\n",
    "    ftag2 = open(new_dir2 + \"/antz0001tag.csv\",\"w\")\n",
    "\n",
    "    # Write the header string\n",
    "    outputstring = \"id,record_id,table_id,title,description\\n\"\n",
    "    ftag1.write(outputstring)\n",
    "    ftag2.write(outputstring)\n",
    "\n",
    "    # Write rows for header, world, camera views (4), and grid to Node file\n",
    "    outputstring = \"id,type,data,selected,parent_id,branch_level,child_id,child_index,child_count,ch_input_id,ch_output_id,ch_last_updated,average,interval,aux_a_x,aux_a_y,aux_a_z,aux_b_x,aux_b_y,aux_b_z,color_shift,rotate_vec_x,rotate_vec_y,rotate_vec_z,rotate_vec_s,scale_x,scale_y,scale_z,translate_x,translate_y,translate_z,tag_offset_x,tag_offset_y,tag_offset_z,rotate_rate_x,rotate_rate_y,rotate_rate_z,rotate_x,rotate_y,rotate_z,scale_rate_x,scale_rate_y,scale_rate_z,translate_rate_x,translate_rate_y,translate_rate_z,translate_vec_x,translate_vec_y,translate_vec_z,shader,geometry,line_width,point_size,ratio,color_index,color_r,color_g,color_b,color_a,color_fade,texture_id,hide,freeze,topo,facet,auto_zoom_x,auto_zoom_y,auto_zoom_z,trigger_hi_x,trigger_hi_y,trigger_hi_z,trigger_lo_x,trigger_lo_y,trigger_lo_z,set_hi_x,set_hi_y,set_hi_z,set_lo_x,set_lo_y,set_lo_z,proximity_x,proximity_y,proximity_z,proximity_mode_x,proximity_mode_y,proximity_mode_z,segments_x,segments_y,segments_z,tag_mode,format_id,table_id,record_id,size\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "    # Row for world parameters\n",
    "    outputstring = \"1,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.1,0,50,101,101,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,16,16,0,0,0,0,0,420\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "    # Row for first camera view\n",
    "    outputstring = \"2,1,2,0,0,0,2,2,3,0,0,0,0,1,0,0,0,0,0,0,0,0,0.008645,0.825266,-0.564678,1,1,1,-32.446629,-180.908295,143.514175,0,0,1,0,0,0,55.620094,0.600200,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.1,0,50,101,101,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,214.306686,0,0,0,0,0,16,16,0,0,0,0,0,420\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "    # Row for second camera view\n",
    "    outputstring = \"3,1,3,0,2,1,3,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,-1,1,1,1,-0.500000,0,571.750000,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.1,0,50,101,101,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,16,0,0,0,0,0,420\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "    # Third camera view\n",
    "    outputstring = \"4,1,4,0,2,1,4,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,-0,1,1,1,0,-90,7,0,0,1,0,0,0,90,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.1,0,50,101,101,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,16,0,0,0,0,0,420\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "    # Fourth camera view\n",
    "    outputstring = \"5,1,5,0,2,1,5,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,-1,-0,-0,1,1,1,85,0,7,0,0,1,0,0,0,90,270,0,0,0,0,0,0,0,-0,0,0,0,0,1,0,0.1,0,50,101,101,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,16,0,0,0,0,0,420\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "    # Default Grid\n",
    "    outputstring = \"6,6,6,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.1,3,0,0,255,150,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,6,0,0,0,0,0,420\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "\n",
    "    # Initialize increments\n",
    "    taginc = 0\n",
    "    id = 6\n",
    "\n",
    "    numlevel1toroids = 0\n",
    "    numlevel2toroids = 6\n",
    "    numlevel3toroids = 0\n",
    "\n",
    "    # Create root axis geometry for tower 'axle'\n",
    "    id += 1\n",
    "    data = id\n",
    "    type = 5\n",
    "    parent_id = 0\n",
    "    selected = 0\n",
    "    branch_level = 0\n",
    "    child_id = id\n",
    "    child_count = 1\n",
    "    ch_input_id = 0\n",
    "    translate_x = 0\n",
    "    translate_y = 0\n",
    "    translate_z = 0\n",
    "    tag_offset_z = 90\n",
    "    color_index = 17\n",
    "    color_var = colortable[color_index]\n",
    "    geometry = 19\n",
    "    ratio = 0.4\n",
    "    scale_x = 7\n",
    "    scale_y = scale_x\n",
    "    scale_z = 1.5*scale_x\n",
    "    rotate_x = 0\n",
    "    rotate_y = 0\n",
    "    topo = 6\n",
    "    color_a = 255\n",
    "    color_var = colortable[color_index]\n",
    "    record_id = id\n",
    "    \n",
    "    # Creat output string and write to ANTz Node File\n",
    "    outputstring = str(id) + \",\" + str(type) + \",\" + str(data) + \",\" + str(selected) + \",\" + str(parent_id) + \",\" + str(branch_level) + \",\" + str(child_id) + \",\" + str(child_index) + \",\" + str(child_count) + \",\" + str(ch_input_id) + \",\" + str(ch_output_id) + \",\" + str(ch_last_updated) + \",\" + str(average) + \",\" + str(interval) + \",\" + str(aux_a_x) + \",\" + str(aux_a_y) + \",\" + str(aux_a_z) + \",\" + str(aux_b_x) + \",\" + str(aux_b_y) + \",\" + str(aux_b_z) + \",\" + str(color_shift) + \",\" + str(rotate_vec_x) + \",\" + str(rotate_vec_y) + \",\" + str(rotate_vec_z) + \",\" + str(rotate_vec_s) + \",\" + str(scale_x) + \",\" + str(scale_y) + \",\" + str(scale_z) + \",\" + str(translate_x) + \",\" + str(translate_y) + \",\" + str(translate_z) + \",\" + str(tag_offset_x) + \",\" + str(tag_offset_y) + \",\" + str(tag_offset_z) + \",\" + str(rotate_rate_x) + \",\" + str(rotate_rate_y) + \",\" + str(rotate_rate_z) + \",\" + str(rotate_x) + \",\" + str(rotate_y) + \",\" + str(rotate_z) + \",\" + str(scale_rate_x) + \",\" + str(scale_rate_y) + \",\" + str(scale_rate_z) + \",\" + str(translate_rate_x) + \",\" + str(translate_rate_y) + \",\" + str(translate_rate_z) + \",\" + str(translate_vec_x) + \",\" + str(translate_vec_y) + \",\" + str(translate_vec_z) + \",\" + str(shader) + \",\" + str(geometry) + \",\" + str(line_width) + \",\" + str(point_size) + \",\" + str(ratio) + \",\" + str(color_index) + \",\" + str(color_var) + \",\" + str(color_a) + \",\" + str(color_fade) + \",\" + str(texture_id) + \",\" + str(hide) + \",\" + str(freeze) + \",\" + str(topo) + \",\" + str(facet) + \",\" + str(auto_zoom_x) + \",\" + str(auto_zoom_y) + \",\" + str(auto_zoom_z) + \",\" + str(trigger_hi_x) + \",\" + str(trigger_hi_y) + \",\" + str(trigger_hi_z) + \",\" + str(trigger_lo_x) + \",\" + str(trigger_lo_y) + \",\" + str(trigger_lo_z) + \",\" + str(set_hi_x) + \",\" + str(set_hi_y) + \",\" + str(set_hi_z) + \",\" + str(set_lo_x) + \",\" + str(set_lo_y) + \",\" + str(set_lo_z) + \",\" + str(proximity_x) + \",\" + str(proximity_y) + \",\" + str(proximity_z) + \",\" + str(proximity_mode_x) + \",\" + str(proximity_mode_y) + \",\" + str(proximity_mode_z) + \",\" + str(segments_x) + \",\" + str(segments_y) + \",\" + str(segments_z) + \",\" + str(tag_mode) + \",\" + str(format_id) + \",\" + str(table_id) + \",\" + str(record_id) + \",\" + str(size) + \"\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "\n",
    "    # Output to Tag file\n",
    "    tagtext = \"i:\" + str(i) + \" Name:\" + twitter_user_array[bot_inc]\n",
    "    tagstring = str(taginc) + \",\" + str(record_id) + \",0,\\\"\" + tagtext + \"\\\",\\\"\\\"\\n\"\n",
    "    ftag1.write(tagstring)\n",
    "    ftag2.write(tagstring)\n",
    "    taginc += 1\n",
    "\n",
    "    # Get id for parent object of branch level 1 objects created below\n",
    "    level0objectid = id\n",
    "    cyclecount = 1\n",
    "    \n",
    "    # Add central reference object with username attached to tag\n",
    "    id += 1\n",
    "    data = id\n",
    "    type = 5\n",
    "    parent_id = id-1\n",
    "    selected = 0\n",
    "    branch_level = 1\n",
    "    child_id = id\n",
    "    child_count = 0\n",
    "    ch_input_id = 0\n",
    "    translate_x = -90\n",
    "    translate_y = 0\n",
    "    translate_z = 0\n",
    "    tag_offset_z = 0\n",
    "    scale_x = 0.1\n",
    "    scale_y = scale_x\n",
    "    scale_z = scale_x\n",
    "    ratio = 0.1\n",
    "    geometry = 11\n",
    "    topo = 7\n",
    "    color_index = 1\n",
    "    color_var = colortable[color_index]\n",
    "    record_id = id\n",
    "    \n",
    "    # Create output string and write to ANTz node file for object to highlight username\n",
    "    outputstring = str(id) + \",\" + str(type) + \",\" + str(data) + \",\" + str(selected) + \",\" + str(parent_id) + \",\" + str(branch_level) + \",\" + str(child_id) + \",\" + str(child_index) + \",\" + str(child_count) + \",\" + str(ch_input_id) + \",\" + str(ch_output_id) + \",\" + str(ch_last_updated) + \",\" + str(average) + \",\" + str(interval) + \",\" + str(aux_a_x) + \",\" + str(aux_a_y) + \",\" + str(aux_a_z) + \",\" + str(aux_b_x) + \",\" + str(aux_b_y) + \",\" + str(aux_b_z) + \",\" + str(color_shift) + \",\" + str(rotate_vec_x) + \",\" + str(rotate_vec_y) + \",\" + str(rotate_vec_z) + \",\" + str(rotate_vec_s) + \",\" + str(scale_x) + \",\" + str(scale_y) + \",\" + str(scale_z) + \",\" + str(translate_x) + \",\" + str(translate_y) + \",\" + str(translate_z) + \",\" + str(tag_offset_x) + \",\" + str(tag_offset_y) + \",\" + str(tag_offset_z) + \",\" + str(rotate_rate_x) + \",\" + str(rotate_rate_y) + \",\" + str(rotate_rate_z) + \",\" + str(rotate_x) + \",\" + str(rotate_y) + \",\" + str(rotate_z) + \",\" + str(scale_rate_x) + \",\" + str(scale_rate_y) + \",\" + str(scale_rate_z) + \",\" + str(translate_rate_x) + \",\" + str(translate_rate_y) + \",\" + str(translate_rate_z) + \",\" + str(translate_vec_x) + \",\" + str(translate_vec_y) + \",\" + str(translate_vec_z) + \",\" + str(shader) + \",\" + str(geometry) + \",\" + str(line_width) + \",\" + str(point_size) + \",\" + str(ratio) + \",\" + str(color_index) + \",\" + str(color_var) + \",\" + str(color_a) + \",\" + str(color_fade) + \",\" + str(texture_id) + \",\" + str(hide) + \",\" + str(freeze) + \",\" + str(topo) + \",\" + str(facet) + \",\" + str(auto_zoom_x) + \",\" + str(auto_zoom_y) + \",\" + str(auto_zoom_z) + \",\" + str(trigger_hi_x) + \",\" + str(trigger_hi_y) + \",\" + str(trigger_hi_z) + \",\" + str(trigger_lo_x) + \",\" + str(trigger_lo_y) + \",\" + str(trigger_lo_z) + \",\" + str(set_hi_x) + \",\" + str(set_hi_y) + \",\" + str(set_hi_z) + \",\" + str(set_lo_x) + \",\" + str(set_lo_y) + \",\" + str(set_lo_z) + \",\" + str(proximity_x) + \",\" + str(proximity_y) + \",\" + str(proximity_z) + \",\" + str(proximity_mode_x) + \",\" + str(proximity_mode_y) + \",\" + str(proximity_mode_z) + \",\" + str(segments_x) + \",\" + str(segments_y) + \",\" + str(segments_z) + \",\" + str(tag_mode) + \",\" + str(format_id) + \",\" + str(table_id) + \",\" + str(record_id) + \",\" + str(size) + \"\\n\"\n",
    "    fout1.write(outputstring)\n",
    "    fout2.write(outputstring)\n",
    "\n",
    "    # Output text to Tag file\n",
    "    tagtext = \"          Twitter Screen Name:\" + twitter_user_array[bot_inc]\n",
    "    tagstring = str(taginc) + \",\" + str(record_id) + \",0,\\\"\" + tagtext + \"\\\",\\\"\\\"\\n\"\n",
    "    ftag1.write(tagstring)\n",
    "    ftag2.write(tagstring)\n",
    "\n",
    "    for tweet in all_tweets:\n",
    "\n",
    "        # Parse the date and time into seconds for total_time and use for translate_y\n",
    "        hour_seconds = float(hour) * 3600\n",
    "        minute_seconds = float(minute) * 60\n",
    "        seconds = float(second) * 1\n",
    "        total_time = (float(seconds) + float(minute_seconds) + float(hour_seconds)) * 360/86400\n",
    "\n",
    "        # Modify relevant ANTz parameters\n",
    "        id += 1\n",
    "        data = id\n",
    "        type = 5\n",
    "        parent_id = level0objectid\n",
    "        selected = 0\n",
    "        branch_level = 1\n",
    "        child_id = id\n",
    "        child_count = numlevel2toroids\n",
    "        ch_input_id = 0\n",
    "        \n",
    "        date_str = tweet['created_at']\n",
    "        year = int(date_str[0:4])\n",
    "        month = int(date_str[5:7])\n",
    "        day = int(date_str[8:10])\n",
    "        hour = int(date_str[11:13])\n",
    "        minute = int(date_str[14:16])\n",
    "        second = int(date_str[17:19])\n",
    "        hour_seconds = hour * 3600\n",
    "        minute_seconds = minute * 60\n",
    "        seconds = second * 1\n",
    "        total_time = (float(seconds) + float(minute_seconds) + float(hour_seconds)) * 360/86400\n",
    "        year_days = (float(year)-2006) * 365\n",
    "        month_days = days_per_numeric_month_cumulative[month]\n",
    "        days = float(day)\n",
    "        total_days = year_days + month_days + days\n",
    "        if days_diff[twitter_user_array[bot_inc]] > 0:\n",
    "            translate_x = (total_days - min_days[twitter_user_array[bot_inc]])*180/days_diff[twitter_user_array[bot_inc]] - 180\n",
    "        else:\n",
    "            translate_x = 0\n",
    "        translate_y = 0\n",
    "        translate_z = 0\n",
    "        tag_offset_z = 0\n",
    "        scale_x = 2.25\n",
    "        scale_y = scale_x\n",
    "        scale_z = scale_x\n",
    "        rotate_x = 90\n",
    "        rotate_y = total_time\n",
    "        ratio = 0.1\n",
    "        geometry = 19\n",
    "        topo = 6\n",
    "\n",
    "        # Determine if spoke tweet object should be green for tweet, white for quoted, light gray for retweeted, dark gray for replied_to\n",
    "        if \"referenced_tweets\" in tweet:\n",
    "            if tweet['referenced_tweets'][0]['type'] == \"retweeted\":\n",
    "                color_index = 25\n",
    "            elif tweet['referenced_tweets'][0]['type'] == \"replied_to\":\n",
    "                color_index = 17\n",
    "            elif tweet['referenced_tweets'][0]['type'] == \"quoted\":\n",
    "                color_index = 16\n",
    "        else:\n",
    "            color_index = 1\n",
    "        color_var = colortable[color_index]\n",
    "        record_id = id\n",
    "        \n",
    "        # Creat output string and write to ANTz Node File\n",
    "        outputstring = str(id) + \",\" + str(type) + \",\" + str(data) + \",\" + str(selected) + \",\" + str(parent_id) + \",\" + str(branch_level) + \",\" + str(child_id) + \",\" + str(child_index) + \",\" + str(child_count) + \",\" + str(ch_input_id) + \",\" + str(ch_output_id) + \",\" + str(ch_last_updated) + \",\" + str(average) + \",\" + str(interval) + \",\" + str(aux_a_x) + \",\" + str(aux_a_y) + \",\" + str(aux_a_z) + \",\" + str(aux_b_x) + \",\" + str(aux_b_y) + \",\" + str(aux_b_z) + \",\" + str(color_shift) + \",\" + str(rotate_vec_x) + \",\" + str(rotate_vec_y) + \",\" + str(rotate_vec_z) + \",\" + str(rotate_vec_s) + \",\" + str(scale_x) + \",\" + str(scale_y) + \",\" + str(scale_z) + \",\" + str(translate_x) + \",\" + str(translate_y) + \",\" + str(translate_z) + \",\" + str(tag_offset_x) + \",\" + str(tag_offset_y) + \",\" + str(tag_offset_z) + \",\" + str(rotate_rate_x) + \",\" + str(rotate_rate_y) + \",\" + str(rotate_rate_z) + \",\" + str(rotate_x) + \",\" + str(rotate_y) + \",\" + str(rotate_z) + \",\" + str(scale_rate_x) + \",\" + str(scale_rate_y) + \",\" + str(scale_rate_z) + \",\" + str(translate_rate_x) + \",\" + str(translate_rate_y) + \",\" + str(translate_rate_z) + \",\" + str(translate_vec_x) + \",\" + str(translate_vec_y) + \",\" + str(translate_vec_z) + \",\" + str(shader) + \",\" + str(geometry) + \",\" + str(line_width) + \",\" + str(point_size) + \",\" + str(ratio) + \",\" + str(color_index) + \",\" + str(color_var) + \",\" + str(color_a) + \",\" + str(color_fade) + \",\" + str(texture_id) + \",\" + str(hide) + \",\" + str(freeze) + \",\" + str(topo) + \",\" + str(facet) + \",\" + str(auto_zoom_x) + \",\" + str(auto_zoom_y) + \",\" + str(auto_zoom_z) + \",\" + str(trigger_hi_x) + \",\" + str(trigger_hi_y) + \",\" + str(trigger_hi_z) + \",\" + str(trigger_lo_x) + \",\" + str(trigger_lo_y) + \",\" + str(trigger_lo_z) + \",\" + str(set_hi_x) + \",\" + str(set_hi_y) + \",\" + str(set_hi_z) + \",\" + str(set_lo_x) + \",\" + str(set_lo_y) + \",\" + str(set_lo_z) + \",\" + str(proximity_x) + \",\" + str(proximity_y) + \",\" + str(proximity_z) + \",\" + str(proximity_mode_x) + \",\" + str(proximity_mode_y) + \",\" + str(proximity_mode_z) + \",\" + str(segments_x) + \",\" + str(segments_y) + \",\" + str(segments_z) + \",\" + str(tag_mode) + \",\" + str(format_id) + \",\" + str(table_id) + \",\" + str(record_id) + \",\" + str(size) + \"\\n\"\n",
    "        fout1.write(outputstring)\n",
    "        fout2.write(outputstring)\n",
    "\n",
    "        # Output to Tag file\n",
    "        tagtext = '<a href=\"https://twitter.com/' + twitter_user_array[bot_inc] + '/status/' + str(tweet['id']) + '\">' + ' Name:' + twitter_user_array[bot_inc] + ' Tweeted:' + str(tweet['created_at']) + '</a>'\n",
    "        tagstring = str(taginc) + \",\" + str(record_id) + \",0,\\\"\" + tagtext + \"\\\",\\\"\\\"\\n\"\n",
    "        ftag1.write(tagstring)\n",
    "        ftag2.write(tagstring)\n",
    "        taginc += 1\n",
    "\n",
    "        # Get id for parent object of branch level 2 objects created below\n",
    "        level1objectid = id\n",
    "\n",
    "        for j in range(numlevel2toroids):\n",
    "            id += 1\n",
    "            data = id\n",
    "            type = 5\n",
    "            parent_id = level1objectid\n",
    "            selected = 0\n",
    "            branch_level = 2\n",
    "            child_id = id\n",
    "            child_count = numlevel3toroids\n",
    "            ch_input_id = 0\n",
    "            translate_x = -25 * j\n",
    "            translate_y = 0\n",
    "            translate_z = 0\n",
    "\n",
    "            # Geometry for number of likes\n",
    "            if j == 0:\n",
    "                if 'public_metrics' in tweet:\n",
    "                    color_index = 7\n",
    "                    tagtext = \"# Likes:\" + str(tweet['public_metrics']['like_count'])\n",
    "                    scale_x = 0.1 + 0.15*np.log(1 + tweet['public_metrics']['like_count'])\n",
    "                    if cyclecount == 1:\n",
    "                        ch_input_id = 3\n",
    "                        color_a = 255\n",
    "                else:\n",
    "                    scale_x = 0\n",
    "                    tagtext = \"No Likes\"\n",
    "                    \n",
    "            # Geometry for number of uppercase characters in tweet text\n",
    "            if j == 1:\n",
    "                num_uppercase = sum(1 for c in tweet['text'] if c.isupper())\n",
    "                color_index = 6\n",
    "                tagtext = \"# UC Chars in tweet:\" + str(num_uppercase)\n",
    "                scale_x = 0.05 * num_uppercase\n",
    "                if cyclecount == 1:\n",
    "                    ch_input_id = 3\n",
    "                    color_a = 255\n",
    "                    \n",
    "            # Geometry for presence of keywords in tweet text\n",
    "            if j == 2:\n",
    "                tagtext = \"#NoHashtags\"\n",
    "                scale_x = 0\n",
    "                color_index = 0\n",
    "                keyword1 = \"Trump\"\n",
    "                keyword2 = \"Biden\"\n",
    "                if \"entities\" in tweet:\n",
    "                    if \"hashtags\" in tweet['entities']:\n",
    "                        for k in range(0,len(tweet['entities']['hashtags'])):\n",
    "                            if re.match(keyword1.lower(), str(tweet['entities']['hashtags'][k]['tag']).lower()):\n",
    "                                scale_x = 2\n",
    "                                color_index = 0\n",
    "                                tagtext = \"#\" + keyword1\n",
    "                            elif re.match(keyword2.lower(), str(tweet['entities']['hashtags'][k]['tag']).lower()):\n",
    "                                scale_x = 2\n",
    "                                color_index = 2\n",
    "                                tagtext = \"#\" + keyword2\n",
    "                    else:\n",
    "                        scale_x = 0\n",
    "                        tagtext = \"No patterns matched\"\n",
    "                else:\n",
    "                    scale_x = 0\n",
    "                    tagtext = \"No patterns matched\"\n",
    "                if re.match(keyword1.lower(), str(tweet['text']).lower()):\n",
    "                    scale_x = 2\n",
    "                    color_index = 0\n",
    "                    tagtext = \"#\" + keyword1\n",
    "                elif re.match(keyword2.lower(), str(tweet['text']).lower()):\n",
    "                    scale_x = 2\n",
    "                    color_index = 2\n",
    "                    tagtext = \"#\" + keyword2\n",
    "                if cyclecount == 1:\n",
    "                    ch_input_id = 4\n",
    "                    color_a = 255\n",
    "\n",
    "            # Geometry for number or URLs\n",
    "            if j == 3:\n",
    "                color_index = 3\n",
    "                if \"entities\" in tweet:\n",
    "                    if \"urls\" in tweet['entities']:\n",
    "                        scale_x = 0.5*len(tweet['entities']['urls'])\n",
    "                        tagtext = '<a href=\"' + tweet['entities']['urls'][0]['url'] + '\">' + tweet['entities']['urls'][0]['url'] + '</a>'\n",
    "                    else:\n",
    "                        scale_x = 0\n",
    "                        tagtext = \"No urls\"\n",
    "                else:\n",
    "                    scale_x = 0\n",
    "                    tagtext = \"No urls\"\n",
    "                if cyclecount == 1:\n",
    "                    ch_input_id = 5\n",
    "                    color_a = 255\n",
    "                    \n",
    "            # Geometry for percent of special characters in tweet text\n",
    "            if j == 4:\n",
    "                color_index = 4\n",
    "                special_char = re.findall(r'[^a-zA-Z0-9 ]', tweet['text'])\n",
    "                total_char = re.findall(r'', tweet['text'])\n",
    "                num_special_char = len(special_char)\n",
    "                num_total_char = len(total_char)\n",
    "                percent_special_char = num_special_char/num_total_char\n",
    "                scale_x = 8 * percent_special_char\n",
    "                tagtext = \"% Special Chars:\" + str(percent_special_char)\n",
    "                if cyclecount == 1:\n",
    "                    ch_input_id = 6\n",
    "                    color_a = 255\n",
    "                    \n",
    "            # Geometry for number of hashtags\n",
    "            if j == 5:\n",
    "                color_index = 5\n",
    "                if \"entities\" in tweet:\n",
    "                    if \"hashtags\" in tweet['entities']:\n",
    "                        scale_x = 0.5*len(tweet['entities']['hashtags'])\n",
    "                        tagtext = \"# hashtags:\" + str(len(tweet['entities']['hashtags']))\n",
    "                    else:\n",
    "                        scale_x = 0\n",
    "                        tagtext = \"No hashtags\"\n",
    "                else:\n",
    "                    scale_x = 0\n",
    "                    tagtext = \"No hashtags\"\n",
    "                if cyclecount == 1:\n",
    "                    ch_input_id = 7\n",
    "                    color_a = 255\n",
    "                cyclecount += 1\n",
    "            scale_y = scale_x\n",
    "            scale_z = 0.5 * scale_x\n",
    "            rotate_x = 0\n",
    "            rotate_y = 0\n",
    "            ratio = 0.1\n",
    "            color_var = colortable[color_index]\n",
    "\n",
    "            geometry = 1\n",
    "            topo = 7\n",
    "            record_id = id\n",
    "            outputstring = str(id) + \",\" + str(type) + \",\" + str(data) + \",\" + str(selected) + \",\" + str(parent_id) + \",\" + str(branch_level) + \",\" + str(child_id) + \",\" + str(child_index) + \",\" + str(child_count) + \",\" + str(ch_input_id) + \",\" + str(ch_output_id) + \",\" + str(ch_last_updated) + \",\" + str(average) + \",\" + str(interval) + \",\" + str(aux_a_x) + \",\" + str(aux_a_y) + \",\" + str(aux_a_z) + \",\" + str(aux_b_x) + \",\" + str(aux_b_y) + \",\" + str(aux_b_z) + \",\" + str(color_shift) + \",\" + str(rotate_vec_x) + \",\" + str(rotate_vec_y) + \",\" + str(rotate_vec_z) + \",\" + str(rotate_vec_s) + \",\" + str(scale_x) + \",\" + str(scale_y) + \",\" + str(scale_z) + \",\" + str(translate_x) + \",\" + str(translate_y) + \",\" + str(translate_z) + \",\" + str(tag_offset_x) + \",\" + str(tag_offset_y) + \",\" + str(tag_offset_z) + \",\" + str(rotate_rate_x) + \",\" + str(rotate_rate_y) + \",\" + str(rotate_rate_z) + \",\" + str(rotate_x) + \",\" + str(rotate_y) + \",\" + str(rotate_z) + \",\" + str(scale_rate_x) + \",\" + str(scale_rate_y) + \",\" + str(scale_rate_z) + \",\" + str(translate_rate_x) + \",\" + str(translate_rate_y) + \",\" + str(translate_rate_z) + \",\" + str(translate_vec_x) + \",\" + str(translate_vec_y) + \",\" + str(translate_vec_z) + \",\" + str(shader) + \",\" + str(geometry) + \",\" + str(line_width) + \",\" + str(point_size) + \",\" + str(ratio) + \",\" + str(color_index) + \",\" + str(color_var) + \",\" + str(color_a) + \",\" + str(color_fade) + \",\" + str(texture_id) + \",\" + str(hide) + \",\" + str(freeze) + \",\" + str(topo) + \",\" + str(facet) + \",\" + str(auto_zoom_x) + \",\" + str(auto_zoom_y) + \",\" + str(auto_zoom_z) + \",\" + str(trigger_hi_x) + \",\" + str(trigger_hi_y) + \",\" + str(trigger_hi_z) + \",\" + str(trigger_lo_x) + \",\" + str(trigger_lo_y) + \",\" + str(trigger_lo_z) + \",\" + str(set_hi_x) + \",\" + str(set_hi_y) + \",\" + str(set_hi_z) + \",\" + str(set_lo_x) + \",\" + str(set_lo_y) + \",\" + str(set_lo_z) + \",\" + str(proximity_x) + \",\" + str(proximity_y) + \",\" + str(proximity_z) + \",\" + str(proximity_mode_x) + \",\" + str(proximity_mode_y) + \",\" + str(proximity_mode_z) + \",\" + str(segments_x) + \",\" + str(segments_y) + \",\" + str(segments_z) + \",\" + str(tag_mode) + \",\" + str(format_id) + \",\" + str(table_id) + \",\" + str(record_id) + \",\" + str(size) + \"\\n\"\n",
    "            fout1.write(outputstring)\n",
    "            fout2.write(outputstring)\n",
    "\n",
    "            ## Output to Tag file\n",
    "            tagstring = str(taginc) + \",\" + str(record_id) + \",0,\\\"\" + tagtext + \"\\\",\\\"\\\"\\n\"\n",
    "            ftag1.write(tagstring)\n",
    "            ftag2.write(tagstring)\n",
    "            taginc += 1\n",
    "            level2objectid = id\n",
    "\n",
    "    fout1.close()\n",
    "    ftag1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Word Count From Tweet Text\n",
    "#### Useful for keywords to use in previous cell code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "username=\"nytimes\"\n",
    "\n",
    "for tweet in all_tweets:\n",
    "    newtext = tweet['text']\n",
    "    text = text + \" \" + newtext\n",
    "\n",
    "stop_words = [\"the\",\"a\",\"of\",\"and\",\"to\",\"in\",\"for\",\"that\",\"on\",\"is\",\"with\",\"at\",\"by\",\"it\",\"as\",\"but\",\"from\",\"be\",\"an\",\"have\",\"was\",\"not\",\"this\",\"are\",\"has\",\"who\",\"they\",\"he\",\"one\",\"said\",\"more\",\"about\",\"or\",\"when\",\"their\",\"his\",\"had\",\"been\",\"all\",\"which\",\"will\",\"out\",\"up\",\"if\",\"than\",\"were\",\"would\",\"can\",\"new\",\"there\",\"after\",\"other\",\"two\",\"some\",\"i\",\"no\",\"into\",\"so\",\"what\",\"also\",\"like\",\"we\",\"its\",\"you\",\"only\",\"over\",\"just\",\"most\",\"them\",\"now\",\"could\",\"because\",\"do\",\"even\",\"before\",\"many\",\"get\",\"where\",\"how\",\"those\",\"any\",\"then\",\"much\",\"made\",\"while\",\"still\",\"may\",\"him\",\"through\",\"since\",\"off\",\"here\",\"did\",\"good\",\"down\",\"these\",\"another\",\"being\",\"such\",\"going\",\"go\",\"think\",\"very\",\"against\",\"our\",\"too\",\"my\",\"both\",\"she\",\"should\",\"under\",\"between\",\"during\",\"her\",\"me\"]\n",
    "word_count = {}\n",
    "\n",
    "# break the string into list of words \n",
    "str1 = text.split()         \n",
    "str2 = []\n",
    "\n",
    "# loop till string values present in list str\n",
    "for i in str1:             \n",
    "    # checking for the duplicacy\n",
    "    if i not in str2:\n",
    "        if i not in stop_words:\n",
    "            # insert value in str2\n",
    "            str2.append(i) \n",
    "\n",
    "for i in range(0, len(str2)):\n",
    "    # count the frequency of each word(present \n",
    "    # in str2) in str1 and print\n",
    "#     print('Frequency of', str2[i], 'is :', str1.count(str2[i]))\n",
    "    word_count[str2[i]] = str1.count(str2[i])\n",
    "\n",
    "wordCount={}\n",
    "sortedList=sorted(word_count.values(), reverse=True)\n",
    "for sortedKey in sortedList:\n",
    "    for key, value in word_count.items():\n",
    "        if value==sortedKey:\n",
    "            wordCount[key]=value\n",
    "    \n",
    "# as requested in comment\n",
    "wordCount = {'wordCount': wordCount}\n",
    "\n",
    "with open(cwdpath + '/' + username + '.json', 'w', encoding=\"utf-8\") as f:\n",
    "     f.write(json.dumps(wordCount)) # use 'json.loads' to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username=\"nytimes\"\n",
    "with open(cwdpath + '/' + username + '.json', 'w', encoding=\"utf-8\") as f:\n",
    "     f.write(json.dumps(wordCount)) # use 'json.loads' to do the reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for tweet in all_tweets:\n",
    "    if \"entities\" in tweet:\n",
    "        if \"urls\" in tweet['entities']:\n",
    "            l = len(tweet['entities']['urls'])\n",
    "            print(str(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip script\n",
    "\n",
    "for i in range(len(twitter_user_array)):\n",
    "    print(\"zip -r \" + twitter_user_array[i] + \".zip \" + twitter_user_array[i] + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create twitter user array\n",
    "\n",
    "for i in range(len(twitter_user_array)):\n",
    "    print(\"'\" + twitter_user_array[i] + \"',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTML for web page\n",
    "\n",
    "for i in range(len(twitter_user_array)):\n",
    "    print(\"<p><p>\\n<h2>Twitter User '\" + twitter_user_array[i] + \"'</h2>\\n<a href=\\\"images/myfollowers/\" + twitter_user_array[i] + \"_1.png\\\">\\n<img src=\\\"images/myfollowers/\" + twitter_user_array[i] + \"_1.png\\\" alt=\\\"image of user \" + twitter_user_array[i] + \"\\\" width=\\\"400\\\" height=\\\"240\\\" class=\\\"cards\\\"/> </a>\\n<a href=\\\"images/myfollowers/\" + twitter_user_array[i] + \"_2.png\\\">\\n<img src=\\\"images/myfollowers/\" + twitter_user_array[i] + \"_2.png\\\" alt=\\\"image of user \" + twitter_user_array[i] + \"\\\" width=\\\"400\\\" height=\\\"240\\\" class=\\\"cards\\\"/></a></p>\")\n",
    "#     print(\"zip -r \" + twitter_user_array[i] + \".zip \" + twitter_user_array[i] + \"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
